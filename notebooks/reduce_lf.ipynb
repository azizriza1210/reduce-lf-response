{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc27432",
   "metadata": {},
   "source": [
    "# <h3><b>Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be3358c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import glob\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import CrossEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b7ad4",
   "metadata": {},
   "source": [
    "# <h3><b>Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d72bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "CHROMA_PERSIST_DIRECTORY = \"../chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22c66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8b8fd",
   "metadata": {},
   "source": [
    "# <h3><b>LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0c590ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized!\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.2\n",
    ")\n",
    "print(\"‚úÖ LLM initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d66f1",
   "metadata": {},
   "source": [
    "# <h3><b>Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a5cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../data/tweets\"\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "df_list = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "combined_df = combined_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6a95dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>image_url</th>\n",
       "      <th>tweet_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>...nah ini yg gw sdh perkirakan kalau ruu ini ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://x.com/M4ngU5il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ternyata hidup emang setiba-tiba itu anjir. ti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://x.com/neubiwaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List alasan pwr dinotice\\n- ibu2 nyekel spandu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://x.com/_defly_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahhh gw pernah debat sama orang di tiktok perk...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://x.com/idamanibuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cobain dirumah, rebahan sambil hafalin RUU TNI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://x.com/Bimmz_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet image_url  \\\n",
       "0  ...nah ini yg gw sdh perkirakan kalau ruu ini ...       NaN   \n",
       "1  ternyata hidup emang setiba-tiba itu anjir. ti...       NaN   \n",
       "2  List alasan pwr dinotice\\n- ibu2 nyekel spandu...       NaN   \n",
       "3  Ahhh gw pernah debat sama orang di tiktok perk...       NaN   \n",
       "4  Cobain dirumah, rebahan sambil hafalin RUU TNI...       NaN   \n",
       "\n",
       "                 tweet_link  \n",
       "0    https://x.com/M4ngU5il  \n",
       "1    https://x.com/neubiwaa  \n",
       "2     https://x.com/_defly_  \n",
       "3  https://x.com/idamanibuu  \n",
       "4      https://x.com/Bimmz_  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ffa8823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ternyata hidup emang setiba-tiba itu anjir. tiba-tiba RUU TNI SAH, tiba-tiba gua juga diselingkuhin ke sekian kalinya AKHH MANTAP'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['tweet'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e692ccd",
   "metadata": {},
   "source": [
    "# <h3><b>Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c1572",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>all-MiniLM-L6-v2</b>\n",
    "<p>This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b756cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saita\\AppData\\Local\\Temp\\ipykernel_21488\\2582161042.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings model loaded\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "print(\"‚úÖ Embeddings model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb5753",
   "metadata": {},
   "source": [
    "# <h3><b>Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12847c2",
   "metadata": {},
   "source": [
    "## <h4><b>Store Data to Vector DB Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23df521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_tweets_to_chromadb(df, embeddings, CHROMA_PERSIST_DIRECTORY):\n",
    "    \"\"\"\n",
    "    Simpan kolom 'tweet' dari DataFrame ke ChromaDB, dengan menghapus duplikat konten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cek kolom 'tweet' ada\n",
    "        if \"tweet\" not in df.columns:\n",
    "            raise ValueError(\"DataFrame tidak memiliki kolom 'tweet'\")\n",
    "\n",
    "        # Konversi setiap baris tweet menjadi Document\n",
    "        documents = [\n",
    "            Document(page_content=str(row[\"tweet\"]), metadata={\"index\": i})\n",
    "            for i, row in df.iterrows()\n",
    "            if pd.notna(row[\"tweet\"]) and str(row[\"tweet\"]).strip() != \"\"\n",
    "        ]\n",
    "\n",
    "        # Load atau buat vector store\n",
    "        try:\n",
    "            vector_store = Chroma(\n",
    "                persist_directory=CHROMA_PERSIST_DIRECTORY,\n",
    "                embedding_function=embeddings,\n",
    "            )\n",
    "            existing_docs = vector_store.get()\n",
    "            print(\"üìÅ ChromaDB ditemukan, memuat koleksi lama...\")\n",
    "        except Exception:\n",
    "            vector_store = None\n",
    "            existing_docs = None\n",
    "            print(\"üÜï Membuat koleksi ChromaDB baru...\")\n",
    "\n",
    "        # Tambahkan dokumen baru\n",
    "        if vector_store is None:\n",
    "            vector_store = Chroma.from_documents(\n",
    "                documents=documents,\n",
    "                embedding=embeddings,\n",
    "                persist_directory=CHROMA_PERSIST_DIRECTORY,\n",
    "            )\n",
    "        else:\n",
    "            vector_store.add_documents(documents)\n",
    "\n",
    "        # üîç Hapus duplikat berdasarkan isi tweet\n",
    "        print(\"üîç Memeriksa duplikat konten...\")\n",
    "        all_docs = vector_store.get()\n",
    "        if all_docs and all_docs.get(\"ids\"):\n",
    "            seen = set()\n",
    "            ids_to_delete = []\n",
    "            for doc_id, content in zip(all_docs[\"ids\"], all_docs[\"documents\"]):\n",
    "                content_norm = content.strip().lower()\n",
    "                if content_norm in seen:\n",
    "                    ids_to_delete.append(doc_id)\n",
    "                else:\n",
    "                    seen.add(content_norm)\n",
    "\n",
    "            if ids_to_delete:\n",
    "                vector_store.delete(ids=ids_to_delete)\n",
    "                print(f\"üóëÔ∏è Menghapus {len(ids_to_delete)} tweet duplikat\")\n",
    "\n",
    "        total_docs = len(vector_store.get()[\"ids\"])\n",
    "        return f\"‚úÖ Berhasil menyimpan {len(documents)} tweet baru ke ChromaDB.\\nüìä Total tweet di database: {total_docs}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Gagal menyimpan ke ChromaDB: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2838951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saita\\AppData\\Local\\Temp\\ipykernel_21488\\3614399157.py:19: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ ChromaDB ditemukan, memuat koleksi lama...\n",
      "üîç Memeriksa duplikat konten...\n",
      "üóëÔ∏è Menghapus 9 tweet duplikat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‚úÖ Berhasil menyimpan 1008 tweet baru ke ChromaDB.\\nüìä Total tweet di database: 999'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_tweets_to_chromadb(combined_df, embeddings, CHROMA_PERSIST_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764e33b",
   "metadata": {},
   "source": [
    "## <h4><b>Load Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb34d29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "vector_store = Chroma(\n",
    "    persist_directory=CHROMA_PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "print(\"Database berhasil dimuat.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf523eb0",
   "metadata": {},
   "source": [
    "## <h4><b>Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23045c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2998a",
   "metadata": {},
   "source": [
    "# <h4><b>Delete Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ff944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Koleksi 'machine_learning_modules' berhasil dihapus dari database.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if os.path.exists(CHROMA_PERSIST_DIRECTORY):\n",
    "        shutil.rmtree(CHROMA_PERSIST_DIRECTORY)\n",
    "        print(f\"‚úÖ ChromaDB di '{CHROMA_PERSIST_DIRECTORY}' berhasil dihapus sepenuhnya.\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Folder ChromaDB tidak ditemukan. Tidak ada yang perlu dihapus.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Gagal menghapus ChromaDB: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5466af15",
   "metadata": {},
   "source": [
    "# <h3><b>Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2ddd774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prompt template loaded from JSON successfully\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"instructions:\n",
    "task: Tugasmu adalah menjawab pertanyaan dari user berdasarkan data tweet yang diberikan. Gunakan informasi dari tweet untuk memberikan jawaban yang akurat dan relevan.\n",
    "persona: Kamu adalah seorang ahli media sosial yang menjawab pertanyaan user dengan detail dan jelas hanya berdasarkan data yang ada di twitter.\n",
    "method: Untuk menjawab pertanyaan, ikuti langkah-langkah berikut:\n",
    "1. Baca pertanyaan user dengan seksama.\n",
    "2. Cari informasi yang relevan dari tweets yang diberikan.\n",
    "3. Susun jawaban yang komprehensif dan mudah dipahami berdasarkan informasi tersebut.\n",
    "4. Jika informasi tidak cukup, katakan bahwa kamu tidak memiliki cukup data untuk menjawab pertanyaan tersebut.\n",
    "output-length: Jawaban harus padat sesuai dengan yang ada di tweets.\n",
    "output-format: sebuah paragraf.\n",
    "inclusion: Penjelasan dari tweets yang relevan dengan pertanyaan dan berikanlah kesimpulan.\n",
    "handle-unknown: Jika informasi yang diberikan tidak cukup untuk menjawab pertanyaan, katakan 'Maaf, saya tidak memiliki cukup informasi untuk menjawab pertanyaan ini.'\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"context:\n",
    "  relevant documents: \"{docs}\"\n",
    "  question: \"{query}\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", user_prompt)\n",
    "])\n",
    "print(\"‚úÖ Prompt template loaded from JSON successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9521646e",
   "metadata": {},
   "source": [
    "# <h3><b>RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10af9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG Chain created!\n"
     ]
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\"Format dokumen untuk context\"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain menggunakan LCEL (LangChain Expression Language)\n",
    "rag_chain = (\n",
    "    {\"docs\": retriever | format_docs, \"query\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG Chain created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c2cfc3",
   "metadata": {},
   "source": [
    "# <h3><b>Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcfed12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    \"\"\"Fungsi untuk bertanya ke chatbot\"\"\"\n",
    "    print(f\"Pertanyaan: {question}\")\n",
    "    \n",
    "    # Get answer\n",
    "    answer = rag_chain.invoke(question)\n",
    "    \n",
    "    # Get source documents\n",
    "    docs = retriever.invoke(question)\n",
    "    print(\"üìö Sumber Tweets:\")\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"Data:\\n{i}. {doc.page_content}\")\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba2caa",
   "metadata": {},
   "source": [
    "# <h3><b>Test Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5184a527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertanyaan: Apakah RUU TNI pantas disahkan?\n",
      "üìö Sumber Tweets:\n",
      "Data:\n",
      "1. siapa suruh ruu tni disahkan\n",
      "Data:\n",
      "2. Akibat RUU TNI disahkan.\n",
      "Data:\n",
      "3. Pantas RUU TNI disahkan untuk mendukung kebijakannya yang kelihatan ambiradul\n",
      "Data:\n",
      "4. ini efek gegara ruu tni disahkan\n",
      "Data:\n",
      "5. Oh iya denger denger RUU polri katanya sedang disusun ,kalau emang ini bener apakah ini akan jadi tandingan utk RUU TNI yg udah di sahkan ?\n",
      "Data:\n",
      "6. akibat RUU TNI di sahkan\n",
      "Data:\n",
      "7. terus kenapa ruu tni disahkan gt, mikir ga efeknya apa?\n",
      "Data:\n",
      "8. Apa gak curiga supaya penolakan RUU TNI jadi kendor\n",
      "Data:\n",
      "9. Daripada RUU TNI Indo yg disahkan, mending sahkan TNI ini ama aku\n",
      "Data:\n",
      "10. udah kelakuan mereka gila kayak gini, eh RUU TNI nya tetap aja disahkan.\n",
      "Jawaban: Berdasarkan informasi dari tweet yang diberikan, terdapat beberapa pendapat yang berbeda-beda mengenai pengesahan RUU TNI. Beberapa tweet menyatakan bahwa RUU TNI pantas disahkan untuk mendukung kebijakan yang dianggap ambivalen, namun banyak juga yang mengekspresikan kekecewaan dan kekhawatiran atas pengesahan RUU TNI, dengan beberapa di antaranya menyatakan bahwa pengesahan tersebut tidak dipertimbangkan dengan baik dan dapat memiliki efek negatif. Oleh karena itu, tidak ada jawaban yang pasti mengenai apakah RUU TNI pantas disahkan, karena pendapat dan perspektif masyarakat terhadap hal ini sangat beragam.\n"
     ]
    }
   ],
   "source": [
    "jawaban = ask_question(\"Apakah RUU TNI pantas disahkan?\")\n",
    "print(f\"Jawaban: {jawaban}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7afdadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertanyaan: Siapa presiden Indonesia?\n",
      "üìö Sumber Tweets:\n",
      "Data:\n",
      "1. Negara lagi kacau-kacaunya, perempuan tidak memiliki rasa aman, mantan presiden dipertanyakan ijazahnya, RUU perampasan aset masih gonjang-ganjing, konflik papua memanas kembali, saling serang antara polisi dan TNI, pedofil-pedofil semakin liar, guru honorer tdk kunjung naik gaji\n",
      "Data:\n",
      "2. Inilah para penghianat Bangsa indonesia , mereka mencari kesempatan ingin memprovokasi Aceh , maluku , Papua merdeka di PBB , 20 tahun pemerintahan sipil \n",
      "Indonesia terlihat pertahanan politik dan ekonomi kt semangkin melemah , elemen PKI turut bermain, syukur RUU TNI sdh rampung\n",
      "Data:\n",
      "3. RUU TNI disahkan atau tarif US terhadap Indonesia jadi 46%?\n",
      "Data:\n",
      "4. JANGAN PANTANG MENYERAH \n",
      "\n",
      "Kami sebagai Warga Negara Indonesia DENGAN TEGAS menolak Revisi Undang-Undang Tentara Nasional Indonesia (RUU TNI)\n",
      "\n",
      "#TolakRUUTNI\n",
      "#TolakRevisiUUTNI\n",
      "#PeringatanDarurat \n",
      "#IndonesiaGelap\n",
      "#TolakDwifungsiABRI\n",
      "Data:\n",
      "5. RUU TNI baik untuk pertahanan Indonesia.\n",
      "Data:\n",
      "6. biarin, suruh siapa dukung presiden sekarang\n",
      "Data:\n",
      "7. Presiden aja ngesahin RUU TNI cepet, lun... Jadi emang suka gitu \n",
      "Data:\n",
      "8. Yth. Ibu, Bapak, Saudara/i #Kawan BRIN\n",
      "\n",
      "Rapat Paripurna DPR RI (Kamis, 20 Maret 2025) secara resmi mengesahkan Rancangan Undang-Undang (RUU) Tentang Perubahan Atas Undang-Undang Nomor 34 Tahun 2004 Tentang Tentara Nasional Indonesia (TNI) menjadi Undang-Undang TNI yang baru,\n",
      "Data:\n",
      "9. Tidak bisa dipungkiri, militer Indonesia perlu dukungan rakyat. Jangan ragu dukung RUU TNI.\n",
      "Data:\n",
      "10. UU TNI tegaskan peran, bukan dwifungsi!  Regulasi ini justru memperkuat profesionalitas TNI tanpa ganggu supremasi sipil. Jangan termakan hoaks! #UUTNI #RUUTNI #IndonesiaTerang #TolakHoaksdanProvokasi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Maaf, saya tidak memiliki cukup informasi untuk menjawab pertanyaan ini. Tidak ada informasi yang secara eksplisit menyebutkan nama presiden Indonesia di dalam tweet yang diberikan.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"Siapa presiden Indonesia?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da2573",
   "metadata": {},
   "source": [
    "# <h3><b>Reduce LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a82ad59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = []\n",
    "queries = []\n",
    "categories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83a1db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized!\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    model_name=\"openai/gpt-oss-120b\",\n",
    "    temperature=0\n",
    ")\n",
    "print(\"‚úÖ LLM initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56557e",
   "metadata": {},
   "source": [
    "## <h4><b>Counterargument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e8c706f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Counterargument:\n",
      "**Counterargument**\n",
      "\n",
      "Pernyataan bahwa ‚Äútidak ada jawaban yang pasti mengenai apakah RUU TNI pantas disahkan, karena pendapat dan perspektif masyarakat sangat beragam‚Äù mengandalkan **argumen ad populum** (argumentum ad populum) ‚Äì yaitu menyimpulkan bahwa kebenaran suatu kebijakan tergantung pada seberapa banyak orang yang setuju atau tidak setuju. Padahal, keputusan tentang undang‚Äëundang seharusnya didasarkan pada analisis faktual, konstitusional, dan kepentingan publik, bukan semata‚Äëmata pada variasi opini publik.\n",
      "\n",
      "Berikut beberapa poin yang menolak kesimpulan tersebut:\n",
      "\n",
      "1. **Kriteria Objektif Lebih Penting daripada Kuantitas Opini**  \n",
      "   - **Keamanan Nasional:** RUU TNI bertujuan memperkuat struktur pertahanan negara. Evaluasi harus mencakup data tentang ancaman keamanan, kesiapan militer, dan kebutuhan operasional, bukan hanya sentimen publik.  \n",
      "   - **Kesesuaian dengan Konstitusi:** Undang‚Äëundang harus diuji terhadap prinsip‚Äëprinsip konstitusional (misalnya, hak asasi manusia, kontrol sipil atas militer). Jika RUU TNI melanggar ketentuan konstitusi, maka tidak pantas disahkan, terlepas dari berapa banyak orang yang mendukungnya.  \n",
      "   - **Efektivitas Kebijakan:** Analisis dampak ekonomi, administratif, dan sosial (misalnya, biaya pertahanan, transparansi anggaran) memberikan dasar yang lebih kuat untuk menilai kelayakan RUU.\n",
      "\n",
      "2. **Keragaman Opini Tidak Menyiratkan Ketidakpastian Ilmiah**  \n",
      "   - Dalam demokrasi, wacana publik memang penting, tetapi **keragaman pendapat** tidak otomatis menghasilkan kebuntuan keputusan. Badan legislatif memiliki mandat untuk menimbang argumen, mengadakan rapat dengar pendapat, dan merujuk pada pakar serta data empiris.  \n",
      "   - Contoh: Undang‚ÄëUndang Kesehatan atau Undang‚ÄëUndang Pendidikan sering kali mendapat pro‚Äë dan kontra yang luas, namun tetap dapat disahkan karena ada **bukti kuat** tentang manfaatnya.\n",
      "\n",
      "3. **Potensi Bias dalam Representasi Tweet**  \n",
      "   - **Sampling bias:** Tweet yang dikumpulkan mungkin tidak mewakili seluruh populasi. Pengguna Twitter cenderung lebih muda, lebih urban, dan lebih aktif secara politik dibandingkan warga negara secara keseluruhan.  \n",
      "   - **Echo chamber:** Algoritma media sosial dapat memperkuat pandangan tertentu, sehingga ‚Äúbanyak juga yang mengekspresikan kekecewaan‚Äù tidak selalu mencerminkan mayoritas atau opini yang paling beralasan.\n",
      "\n",
      "4. **Perlu Pendekatan Analitis, Bukan Hanya Emosional**  \n",
      "   - Kritik yang menyebutkan ‚Äúpengesahan tersebut tidak dipertimbangkan dengan baik‚Äù harus diikuti dengan **pertanyaan konkret**: Apa saja aspek yang belum dipertimbangkan? Apakah ada studi dampak yang belum dilakukan?  \n",
      "   - Sebaliknya, pendukung yang menyatakan ‚Äúpantas disahkan untuk mendukung kebijakan yang dianggap ambivalen‚Äù perlu menjelaskan **apa yang dimaksud dengan ‚Äúambivalen‚Äù** dan mengapa ambivalensi itu menjadi alasan kuat untuk persetujuan.\n",
      "\n",
      "5. **Kesimpulan yang Dapat Ditarik**  \n",
      "   - Meskipun opini publik beragam, hal itu **tidak menutup kemungkinan** untuk mencapai keputusan yang berlandaskan fakta, hukum, dan kepentingan nasional.  \n",
      "   - Oleh karena itu, alih‚Äëalih menyatakan ‚Äútidak ada jawaban pasti,‚Äù sebaiknya dilakukan **penilaian kritis** terhadap isi RUU TNI, menguji konsistensinya dengan konstitusi, meninjau data keamanan, serta melibatkan pakar dan stakeholder yang relevan.  \n",
      "   - Hasil penilaian tersebut akan memberikan **jawaban yang lebih definitif** mengenai kelayakan pengesahan RUU TNI, terlepas dari variasi pendapat di media sosial.\n",
      "\n",
      "üí¨ Analytical Query:\n",
      "**Query:**  \n",
      "How does the counterargument expose the logical shortcomings in the original claim‚Äîspecifically its reliance on an ad‚ÄØpopulum appeal, sampling bias from Twitter, and the absence of objective, fact‚Äëbased criteria‚Äîwhen asserting that ‚Äúthere is no definitive answer about whether the RUU‚ÄØTNI should be passed because public opinion is diverse‚Äù?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "generate_counterargument = PromptTemplate(\n",
    "    input_variables=[\"response_chatbot\"],\n",
    "    template=\"\"\"\n",
    "I‚Äôll give you some texts. The texts can be question and answer pairs or sentences. \n",
    "The text may contain logical fallacies. Represent the counterargument to the text.\n",
    "\n",
    "Text: \"Annie must like Starbucks because all girls like Starbucks\"\n",
    "Counterargument: \"Not all girls like Starbucks, as personal preferences vary among individuals. \n",
    "Even if Annie is a girl, it does not automatically mean that she likes Starbucks. \n",
    "She may prefer a different type of coffee or may not like coffee at all. \n",
    "It is not fair to make assumptions about someone based on their gender.\"\n",
    "\n",
    "Text: \"{response_chatbot}\"\n",
    "Counterargument:\n",
    "\"\"\"\n",
    ")\n",
    "gce_chain = LLMChain(llm=llm, prompt=generate_counterargument, output_key=\"counterargument\")\n",
    "\n",
    "query_counterargument = PromptTemplate(\n",
    "    input_variables=[\"response_chatbot\", \"counterargument\"],\n",
    "    template=\"\"\"\n",
    "I‚Äôll give you some texts and their counterarguments. \n",
    "The texts can be question and answer pairs or sentences. \n",
    "Create one analytical query for each text to evaluate the reasoning behind it, \n",
    "based on its counterargument.\n",
    "\n",
    "Text: \"Annie must like Starbucks because all girls like Starbucks\"\n",
    "Counterargument: \"Not all girls like Starbucks, as personal preferences vary among individuals. \n",
    "Even if Annie is a girl, it does not automatically mean that she likes Starbucks.\"\n",
    "Query: \"How does the counterargument challenge the assumption that all girls like Starbucks?\"\n",
    "\n",
    "Text: \"{response_chatbot}\"\n",
    "Counterargument: \"{counterargument}\"\n",
    "Query:\n",
    "\"\"\"\n",
    ")\n",
    "qce_chain = LLMChain(llm=llm, prompt=query_counterargument, output_key=\"query_counterargument\")\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[gce_chain, qce_chain],\n",
    "    input_variables=[\"response_chatbot\"],\n",
    "    output_variables=[\"counterargument\", \"query_counterargument\"]\n",
    ")\n",
    "\n",
    "input_text = jawaban \n",
    "\n",
    "result = overall_chain(\n",
    "    {\"response_chatbot\": input_text}\n",
    ")\n",
    "\n",
    "categories.append(\"Counterargument\")\n",
    "generations.append(result[\"counterargument\"])\n",
    "queries.append(result[\"query_counterargument\"])\n",
    "\n",
    "print(\"üß† Counterargument:\")\n",
    "print(result[\"counterargument\"])\n",
    "print(\"\\nüí¨ Analytical Query:\")\n",
    "print(result[\"query_counterargument\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a2855",
   "metadata": {},
   "source": [
    "## <h4><b>Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8db690ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Explanation:\n",
      "**Text 1**  \n",
      "*‚ÄúAnnie must like Starbucks because all girls like Starbucks.‚Äù*  \n",
      "\n",
      "**Identified fallacy / problem**  \n",
      "- **Hasty Generalization / Over‚Äëgeneralization** ‚Äì The premise ‚Äúall girls like Starbucks‚Äù is an unwarranted universal claim that is not supported by evidence.  \n",
      "- **Stereotyping / Gender‚Äëbased bias** ‚Äì It treats ‚Äúgirls‚Äù as a monolithic group with identical preferences, ignoring individual variation.  \n",
      "- **Affirming the consequent (implicit)** ‚Äì From ‚ÄúIf someone is a girl, then they like Starbucks‚Äù (the assumed rule) the argument concludes ‚ÄúAnnie likes Starbucks‚Äù simply because she is a girl. The rule itself is false, so the inference is invalid.\n",
      "\n",
      "**Why the explanation given is appropriate**  \n",
      "The provided explanation correctly points out that the argument relies on an unfounded, sweeping generalization about a gender group and then applies that stereotype to a specific individual without any direct evidence. This is a classic case of stereotyping that can reinforce harmful assumptions.\n",
      "\n",
      "---\n",
      "\n",
      "**Text 2**  \n",
      "*‚ÄúBerdasarkan informasi dari tweet yang diberikan, terdapat beberapa pendapat yang berbeda‚Äëberda‚Ä¶ (translation: ‚ÄúBased on the information from the tweets provided, there are several differing opinions about the passage of the TNI Bill‚Ä¶ Therefore, there is no definite answer as to whether the TNI Bill should be passed, because public opinion is very diverse.‚Äù)*  \n",
      "\n",
      "**Analysis of logical structure**\n",
      "\n",
      "| Component | Content | Evaluation |\n",
      "|-----------|---------|------------|\n",
      "| **Premise** | *‚ÄúTweets show a mix of support and criticism for the TNI Bill.‚Äù* | This is a factual observation about the diversity of expressed opinions on social media. |\n",
      "| **Implicit assumption** | *‚ÄúIf public opinion is divided, then we cannot determine a correct answer.‚Äù* | This is the key inferential step that needs scrutiny. |\n",
      "| **Conclusion** | *‚ÄúTherefore, there is no definite answer whether the TNI Bill should be passed.‚Äù* | The conclusion follows from the premise only if the premise is taken to be sufficient for epistemic closure. |\n",
      "\n",
      "**Logical issues / fallacies**\n",
      "\n",
      "1. **Appeal to Popular Opinion (Argumentum ad Populum) ‚Äì partial**  \n",
      "   - The argument does **not** claim the bill is right or wrong because many people think so; rather, it claims we cannot know the right answer because opinions differ. This is the *inverse* of the usual ad populum, but it still treats the distribution of opinions as a decisive epistemic factor, which is not logically warranted.\n",
      "\n",
      "2. **Argument from Ignorance (Argumentum ad Ignorantiam) ‚Äì ‚ÄúNo evidence ‚Üí No answer‚Äù**  \n",
      "   - The statement ‚Äúthere is no definite answer‚Äù is presented as a conclusion because the available evidence (tweets) is inconclusive. This is an *argument from lack of evidence*: the absence of a consensus in the cited source does not prove that a definitive answer does not exist; it merely shows that the cited source is insufficient.\n",
      "\n",
      "3. **Equivocation / Ambiguity**  \n",
      "   - The phrase ‚Äúdefinite answer‚Äù is vague. Does it refer to a moral judgment, a legal determination, or a factual prediction about outcomes? The argument conflates *policy correctness* with *public consensus*, treating them as interchangeable.\n",
      "\n",
      "4. **False Dilemma (Implicit)**  \n",
      "   - Implicitly the text suggests only two possibilities: (a) unanimous public support ‚Üí a definite answer, or (b) divided public opinion ‚Üí no answer. In reality, a definitive answer could be reached through expert analysis, constitutional review, empirical impact studies, etc., regardless of public opinion.\n",
      "\n",
      "5. **Appeal to Authority (Misplaced)**  \n",
      "   - The source of the information is ‚Äútweets,‚Äù which are informal, unverified statements. Using them as the sole basis for a conclusion about the legitimacy of a national law gives undue weight to a low‚Äëcredibility source.\n",
      "\n",
      "**Strengths of the argument**\n",
      "\n",
      "- **Accurate observation of pluralism** ‚Äì It correctly notes that social media reflects a range of viewpoints, which is an important contextual fact for any public‚Äëpolicy discussion.\n",
      "- **Cautious tone** ‚Äì By refusing to assert a definitive stance, the statement avoids over‚Äëreaching beyond the evidence presented.\n",
      "\n",
      "**How the reasoning could be improved**\n",
      "\n",
      "1. **Separate epistemic claim from descriptive claim**  \n",
      "   - *Descriptive*: ‚ÄúTweets show mixed reactions to the TNI Bill.‚Äù  \n",
      "   - *Epistemic*: ‚ÄúBased solely on these tweets, we cannot determine the normative correctness of the bill; additional legal, strategic, and empirical analyses are required.‚Äù\n",
      "\n",
      "2. **Specify the standard for a ‚Äúdefinite answer.‚Äù**  \n",
      "   - Clarify whether the answer sought is a legal judgment, a policy recommendation, or a prediction of outcomes. Different standards (constitutional compliance, strategic necessity, public welfare) would require different evidence.\n",
      "\n",
      "3. **Acknowledge other sources of evidence**  \n",
      "   - Mention that expert testimony, legislative debates, impact assessments, and constitutional reviews are more appropriate bases for deciding the bill‚Äôs merit than social‚Äëmedia sentiment alone.\n",
      "\n",
      "4. **Avoid implying that lack of consensus equals lack of truth**  \n",
      "   - Reframe: ‚ÄúPublic opinion is divided, which highlights the controversy, but the truth of the bill‚Äôs merits must be evaluated on substantive criteria, not on consensus alone.‚Äù\n",
      "\n",
      "**Re‚Äëwritten version (more logically robust)**  \n",
      "\n",
      "> ‚ÄúThe tweets we examined reveal a spectrum of opinions about the proposed TNI Bill: some users argue it should be passed to support certain policies, while many others express disappointment and concern, warning of possible negative effects. This diversity shows that the issue is contested in public discourse. However, the presence of divergent social‚Äëmedia commentary does not, by itself, determine whether the bill is constitutionally sound or strategically advisable. A definitive assessment requires systematic analysis of the bill‚Äôs legal provisions, security implications, and empirical evidence, in addition to the viewpoints expressed by the public.‚Äù\n",
      "\n",
      "**Summary**\n",
      "\n",
      "- The first text exemplifies a classic hasty generalization and gender stereotyping.  \n",
      "- The second text, while correctly noting a plurality of opinions, commits several logical missteps: it treats the lack of consensus in a low‚Äëcredibility source as proof that no definitive answer exists (argument from ignorance), creates a false dilemma between public opinion and truth, and relies on an equivocal notion of ‚Äúdefinite answer.‚Äù Strengthening the argument involves separating descriptive observations from normative conclusions, clarifying the evidential standards needed, and incorporating higher‚Äëquality sources of analysis.\n",
      "\n",
      "üí¨ Analytical Query:\n",
      "**Query‚ÄØ1 (for the ‚ÄúAnnie must like Starbucks‚Ä¶‚Äù text)**  \n",
      "*How does this text perpetuate harmful gender stereotypes and restrict individual expression?*  \n",
      "\n",
      "---\n",
      "\n",
      "**Query‚ÄØ2 (for the Indonesian ‚ÄúBerdasarkan informasi dari tweet‚Ä¶‚Äù text)**  \n",
      "*Examine the logical structure of this passage. Which fallacies or reasoning problems are present (e.g., appeal to popular opinion, argument from ignorance, false dilemma, equivocation, misuse of authority), and how do they affect the validity of the conclusion? Additionally, suggest how the argument could be revised to separate descriptive observations from normative claims and to rely on stronger evidence.*\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "generate_explanation = PromptTemplate(\n",
    "    input_variables=[\"response_chatbot\"],\n",
    "    template=\"\"\"\n",
    "I‚Äôll give you some texts. The texts can be question and answer pairs or sentences. \n",
    "The text may contain logical fallacies. Analyze thetext.\n",
    "\n",
    "Text: \"Annie must like Starbucks because all girls like Starbucks\"\n",
    "Explanation: \"This text suggests a generalization about girls and their preferences for Starbucks, assuming that Annie, as a girl, must also like Starbucks without evidence. This could be seen as stereotyping, making unfounded assumptions based on gender, reinforcing harmful stereotypes.\"\n",
    "\n",
    "Text: \"{response_chatbot}\"\n",
    "Explanation:\n",
    "\"\"\"\n",
    ")\n",
    "gex_chain = LLMChain(llm=llm, prompt=generate_explanation, output_key=\"explanation\")\n",
    "\n",
    "query_explanation = PromptTemplate(\n",
    "    input_variables=[\"response_chatbot\", \"explanation\"],\n",
    "    template=\"\"\"\n",
    "I‚Äôll give you some texts and their explanations. The texts can be question and answer pairs or sentences.  Create one query for each text to analyze the text based on its explanations.\n",
    "\n",
    "Text: \"Annie must like Starbucks because all girls like Starbucks\"\n",
    "Explanation: \"This text suggests a generalization about girls and their preferences for Starbucks, assuming that Annie, as a girl, must also like Starbucks without evidence. This could be seen as stereotyping, making unfounded assumptions based on gender, reinforcing harmful stereotypes.\"\n",
    "Query: \"How does this text perpetuate harmful gender stereotypes and restrict individual expression?\"\n",
    "\n",
    "Text: \"{response_chatbot}\"\n",
    "Explanation: \"{explanation}\"\n",
    "Query:\n",
    "\"\"\"\n",
    ")\n",
    "qex_chain = LLMChain(llm=llm, prompt=query_explanation, output_key=\"query_explanation\")\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[gex_chain, qex_chain],\n",
    "    input_variables=[\"response_chatbot\"],\n",
    "    output_variables=[\"explanation\", \"query_explanation\"]\n",
    ")\n",
    "\n",
    "input_text = jawaban \n",
    "\n",
    "result = overall_chain(\n",
    "    {\"response_chatbot\": input_text}\n",
    ")\n",
    "\n",
    "categories.append(\"Explanation\")\n",
    "generations.append(result[\"explanation\"])\n",
    "queries.append(result[\"query_explanation\"])\n",
    "\n",
    "print(\"üß† Explanation:\")\n",
    "print(result[\"explanation\"])\n",
    "print(\"\\nüí¨ Analytical Query:\")\n",
    "print(result[\"query_explanation\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1acec1d",
   "metadata": {},
   "source": [
    "## <h4><b>Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7a387b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Goal:\n",
      "**Goal:** To present a balanced overview of the diverse public opinions expressed on Twitter regarding the approval of the RUU‚ÄØTNI, emphasizing that there is no clear consensus or definitive answer about whether the bill should be passed.\n",
      "\n",
      "üí¨ Analytical Query:\n",
      "**Query:**  \n",
      "How well does the text provide a balanced overview of the varied Twitter opinions on the approval of the RUU‚ÄØTNI, and does it clearly convey that there is no definitive consensus or answer regarding whether the bill should be passed?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "generate_goal = PromptTemplate(\n",
    "    input_variables=[\"response_chatbot\"],\n",
    "    template=\"\"\"\n",
    "I‚Äôll give you some texts. The texts can be question and answer pairs or sentences. \n",
    "The text may contain logical fallacies. Express the goal of the text.\n",
    "\n",
    "Text: \"Annie must like Starbucks because all girls like Starbucks\"\n",
    "Goal: \"The goal is to make a generalization about girls liking Starbucks based on the assumption that Annie is a girl.\"\n",
    "\n",
    "Text: \"{response_chatbot}\"\n",
    "Goal:\n",
    "\"\"\"\n",
    ")\n",
    "gg_chain = LLMChain(llm=llm, prompt=generate_goal, output_key=\"goal\")\n",
    "\n",
    "query_goal = PromptTemplate(\n",
    "    input_variables=[\"response_chatbot\", \"goal\"],\n",
    "    template=\"\"\"I‚Äôll give you some texts and their goals.The texts can be question and answer pairs or sentences. Create one query for each text to analyze the text based on its goal.\n",
    "\n",
    "Text: \"Annie must like Starbucks because all girls like Starbucks\"\n",
    "Goal: \"The goal is to make a generalization about girls liking Starbucks based on the assumption that Annie is a girl.\"\n",
    "Query: \"What does this text reveal about the speaker‚Äôs attitude towards girls and their preferences?\"\n",
    "\n",
    "Text: \"{response_chatbot}\"\n",
    "Goal: \"{goal}\"\n",
    "Query:\n",
    "\"\"\"\n",
    ")\n",
    "qg_chain = LLMChain(llm=llm, prompt=query_goal, output_key=\"query_goal\")\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[gg_chain, qg_chain],\n",
    "    input_variables=[\"response_chatbot\"],\n",
    "    output_variables=[\"goal\", \"query_goal\"]\n",
    ")\n",
    "\n",
    "input_text = jawaban \n",
    "\n",
    "result = overall_chain(\n",
    "    {\"response_chatbot\": input_text}\n",
    ")\n",
    "\n",
    "categories.append(\"Goal\")\n",
    "generations.append(result[\"goal\"])\n",
    "queries.append(result[\"query_goal\"])\n",
    "\n",
    "print(\"üß† Goal:\")\n",
    "print(result[\"goal\"])\n",
    "print(\"\\nüí¨ Analytical Query:\")\n",
    "print(result[\"query_goal\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53080a00",
   "metadata": {},
   "source": [
    "## <h4><b>Logical Fallacy Multi-Class Classification from Counterargument, Explanation, and Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fed1e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Appeal to Popularity, Confident Score: 0.92\n",
      "Label: Argument from ignorance, Confident Score: 0.78\n",
      "Label: No Fallacy, Confident Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "logical_fallacy_labels = []\n",
    "confident_scores = []\n",
    "for query in queries:\n",
    "    prompt = f\"\"\"Logical Fallacy Multi-Class Classification\n",
    "    Your task is to classify the type of logical fallacy in the Text. Please classify the type of fallacy in the Text based on the Query.  \n",
    "    Text: {jawaban}\n",
    "    Formulated Prompt: {query}\n",
    "    Label:\n",
    "    Confident Score: \n",
    "\n",
    "    Return only the name of the label and confident score, and nothing else. MAKE SURE your output is one of the logical fallacy and numeric confident score probability seperate with \",\".\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    results = response.content.split(\",\")\n",
    "    logical_fallacy_labels.append(results[0])\n",
    "    confident_scores.append(float(results[1]))\n",
    "    print(f\"Label: {results[0]}, Confident Score: {results[1]}\")\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ded62",
   "metadata": {},
   "source": [
    "## <h4><b>Logical Fallacy Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "80a1784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Logical Fallacy Label Detection: Appeal to Popularity\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Given a sentence with a logical fallacy, we aim to detect it using queries based on multiple perspectives, such as counterargument, explanation, and goal. The ranking information indicates the order of queries based on their confidence scores, which are helpful in identifying the specific\n",
    "type of logical fallacy present in the sentence. Based on the ranking information of these queries, please reference them to detect the fallacy in the sentence.\n",
    "Text: {jawaban}\n",
    "Formulated Prompt:\n",
    "‚Äì Counterargument Query: {queries[0]}\n",
    "‚Äì Explanation Query: {queries[1]}\n",
    "‚Äì Goal Query: {queries[2]}\n",
    "\n",
    "Ranking Information: \n",
    "Counterargument Query: {confident_scores[0]} with label {logical_fallacy_labels[0]},\n",
    "Explanation Query: {confident_scores[1]} with label {logical_fallacy_labels[1]},\n",
    "Goal Query: {confident_scores[2]} with label {logical_fallacy_labels[2]}. \n",
    "\n",
    "Label:\n",
    "\n",
    "Return only the name of the label, and nothing else. MAKE SURE your output is one of the logical fallacy.\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "final_label = response.content\n",
    "print(f\"Final Logical Fallacy Label Detection: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bc7869",
   "metadata": {},
   "source": [
    "# <h3><b>Modify Respons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff5583",
   "metadata": {},
   "source": [
    "## <h4><b>Thematic Progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f16fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**klausa**  \n",
      "1. **Theme:** *Berdasarkan informasi dari tweet yang diberikan*  \n",
      "   **Rheme:** *terdapat beberapa pendapat yang berbeda‚Äëbeda mengenai pengesahan RUU TNI.*  \n",
      "\n",
      "2. **Theme:** *Beberapa tweet*  \n",
      "   **Rheme:** *menyatakan bahwa RUU TNI pantas disahkan untuk mendukung kebijakan yang dianggap ambivalen.*  \n",
      "\n",
      "3. **Theme:** *namun banyak juga yang*  \n",
      "   **Rheme:** *mengekspresikan kekecewaan dan kekhawatiran atas pengesahan RUU TNI.*  \n",
      "\n",
      "4. **Theme:** *dengan beberapa di antaranya*  \n",
      "   **Rheme:** *menyatakan bahwa pengesahan tersebut tidak dipertimbangkan dengan baik dan dapat memiliki efek negatif.*  \n",
      "\n",
      "5. **Theme:** *Oleh karena itu*  \n",
      "   **Rheme:** *tidak ada jawaban yang pasti mengenai apakah RUU TNI pantas disahkan, karena pendapat dan perspektif masyarakat terhadap hal ini sangat beragam.*  \n",
      "\n",
      "**pola_tp**  \n",
      "- **Linear:** 1‚ÄØ‚Üí‚ÄØ2 (rheme klausa‚ÄØ1 menjadi basis topik bagi theme klausa‚ÄØ2).  \n",
      "- **Contrastive/Linear:** 2‚ÄØ‚Üí‚ÄØ3 (peralihan tema dengan konjungsi ‚Äúnamun‚Äù, tetap melanjutkan informasi).  \n",
      "- **Derived:** 3‚ÄØ‚Üí‚ÄØ4 (theme ‚Äúdengan beberapa di antaranya‚Äù merujuk pada sub‚Äëkelompok yang disebutkan di klausa‚ÄØ3).  \n",
      "- **Consequence/Linear:** 4‚ÄØ‚Üí‚ÄØ5 (theme ‚ÄúOleh karena itu‚Äù menandakan konsekuensi dari rheme klausa‚ÄØ4).  \n",
      "\n",
      "**problems**  \n",
      "1. **brand new theme** (klausul‚ÄØ2) ‚Äì theme ‚ÄúBeberapa tweet‚Äù belum muncul sebelumnya; meskipun logis, transisi tidak ditandai dengan penghubung eksplisit.  \n",
      "2. **thematization of rheme** (klausul‚ÄØ3) ‚Äì theme ‚Äúnamun banyak juga yang‚Äù mengambil ide dari rheme sebelumnya tanpa penanda transisi yang kuat, berpotensi menimbulkan kebingungan koherensi.  \n",
      "3. **missing explicit link** (klausul‚ÄØ1‚ÄØ‚Üí‚ÄØ2) ‚Äì tidak ada konjungsi atau kata penanda (mis. ‚Äúkarena‚Äù, ‚Äúsehingga‚Äù) yang menghubungkan pendapat yang berbeda‚Äëbeda dengan tweet yang menyatakan pendapat; hal ini dapat memperlemah alur logis.  \n",
      "\n",
      "**feedback_progression**  \n",
      "Secara keseluruhan teks menunjukkan pola progresi tematik yang beragam (linear, contrastive, derived, consequence) sehingga menjaga koherensi makro. Namun, dua titik lemah muncul: (a) introduksi tema baru pada klausa‚ÄØ2 tanpa penanda transisi, dan (b) peralihan tema pada klausa‚ÄØ3 yang mengubah rheme menjadi theme tanpa sinyal kontrastif yang jelas. Disarankan menambahkan penghubung seperti ‚Äúsebagai contoh,‚Äù atau ‚Äúdi sisi lain,‚Äù pada klausa‚ÄØ2, serta menggunakan ‚Äúmeskipun‚Äù atau ‚Äúakan tetapi‚Äù secara lebih eksplisit pada klausa‚ÄØ3 untuk memperjelas hubungan antar‚Äëklausa dan mengurangi risiko brand‚Äënew‚Äëtheme serta thematization‚Äëof‚Äërheme.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"instructions:\n",
    "  task: \"Identifikasi theme-rheme structure, pola thematic progression, dan masalah-masalah thematic progression.\"\n",
    "  persona: \"Ahli linguistik dengan spesialisasi dalam analisis thematic progression dan struktur kalimat.\"\n",
    "  method: >\n",
    "    Analisis bertahap:\n",
    "      (1) Identifikasi theme dan rheme pada setiap klausa,\n",
    "      (2) Klasifikasi jenis theme,\n",
    "      (3) Analisis pola thematic progression,\n",
    "      (4) Identifikasi masalah thematic progression berdasarkan 12 kategori masalah.\n",
    "  output_format: \"paragraf dengan isian: 'klausa', 'pola_tp', 'problems', dan 'feedback_progression'.\"\n",
    "  handling_unknown: \"Jika kalimat ambigu, berikan alternatif analisis dengan tingkat kepercayaan.\"\n",
    "\n",
    "context:\n",
    "  relevant_information:\n",
    "    definisi_klausa: \"Klausa adalah satuan yang memiliki subjek dan predikat.\"\n",
    "    definisi_theme_rheme: \"Theme adalah elemen awal klausa yang menunjukkan topik, sedangkan rheme memberi informasi baru.\"\n",
    "    definisi_pola_thematic_progression: \"Thematic progression menunjukkan hubungan antar klausa untuk menjaga koherensi teks.\"\n",
    "    thematic_progression_problems:\n",
    "      brand_new_theme: \"Munculnya tema baru tanpa hubungan dengan klausa sebelumnya.\"\n",
    "      thematization_of_rheme: \"Kesalahan menjadikan rheme sebagai theme tanpa transisi yang tepat.\"\n",
    "\n",
    "examples:\n",
    "  respons_chatbot: >\n",
    "    Membahas pengaruh RUU TNI terhadap hubungan TNI dan POLRI jelas tidak relevan,\n",
    "    apalagi jika disuarakan oleh orang-orang yang selama ini dikenal hanya mengejar kepentingan pribadi dan elit militer.\n",
    "  klausa:\n",
    "    - theme: \"Membahas pengaruh RUU TNI terhadap hubungan TNI dan POLRI jelas tidak relevan\"\n",
    "      rheme: \"apalagi jika disuarakan oleh orang-orang yang selama ini dikenal hanya mengejar kepentingan pribadi dan elit militer\"\n",
    "    - theme: \"Mereka yang membela RUU ini\"\n",
    "      rheme: \"bukan benar-benar peduli pada keamanan nasional, tapi hanya ingin menjaga posisi dan akses terhadap kekuasaan\"\n",
    "    - theme: \"Jadi, sulit untuk mempercayai argumen mereka\"\n",
    "      rheme: \"ketika mereka sendiri selama ini terbukti tidak pernah berpihak pada kepentingan rakyat\"\n",
    "  pola_tp:\n",
    "    Constant: \"Terjadi antara Klausa 2 ke 3 dengan theme yang sama.\"\n",
    "    Linear: \"Terjadi antara Klausa 1 ke 2, di mana rheme klausa 1 menjadi theme klausa 2.\"\n",
    "    Split: \"Tidak terjadi.\"\n",
    "    Derived: \"Tidak terjadi.\"\n",
    "  problems:\n",
    "    - masalah: \"brand new theme\"\n",
    "      penjelasan: \"Theme klausa 2 ('membela RUU TNI') tidak pernah disebutkan sebelumnya.\"\n",
    "\n",
    "input_queries:\n",
    "  respons_chatbot: > {jawaban}\n",
    "  klausa: []\n",
    "  pola_tp:\n",
    "    Constant: \"\"\n",
    "    Linear: \"\"\n",
    "    Split: \"\"\n",
    "    Derived: \"\"\n",
    "  problems:\n",
    "    - masalah: \"\"\n",
    "      penjelasan: \"\"\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "tp_problems = response.content \n",
    "print(f\"{tp_problems}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73b204",
   "metadata": {},
   "source": [
    "## <h4><b>Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "927eebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**respons_chatbot**  \n",
      "Berdasarkan informasi dari tweet yang diberikan, terdapat beberapa pendapat yang berbeda‚Äëbeda mengenai pengesahan RUU TNI. Beberapa tweet menyatakan bahwa RUU TNI pantas disahkan untuk mendukung kebijakan yang dianggap ambivalen, namun banyak juga yang mengekspresikan kekecewaan dan kekhawatiran atas pengesahan RUU TNI, dengan beberapa di antaranya menyatakan bahwa pengesahan tersebut tidak dipertimbangkan dengan baik dan dapat memiliki efek negatif. Oleh karena itu, tidak ada jawaban yang pasti mengenai apakah RUU TNI pantas disahkan, karena pendapat dan perspektif masyarakat terhadap hal ini sangat beragam.  \n",
      "\n",
      "**respons_chatbot_sebelumnya**  \n",
      "Berdasarkan informasi dari tweet yang diberikan, terdapat beberapa pendapat yang berbeda‚Äëbeda mengenai pengesahan RUU TNI. Beberapa tweet menyatakan bahwa RUU TNI pantas disahkan untuk mendukung kebijakan yang dianggap ambivalen, namun banyak juga yang mengekspresikan kekecewaan dan kekhawatiran atas pengesahan RUU TNI, dengan beberapa di antaranya menyatakan bahwa pengesahan tersebut tidak dipertimbangkan dengan baik dan dapat memiliki efek negatif. Oleh karena itu, tidak ada jawaban yang pasti mengenai apakah RUU TNI pantas disahkan, karena pendapat dan perspektif masyarakat terhadap hal ini sangat beragam.  \n",
      "\n",
      "**respons_chatbot_setelahnya**  \n",
      "Berdasarkan informasi dari tweet yang diberikan, terdapat beragam pendapat mengenai pengesahan RUU TNI. **Sebagai contoh**, beberapa tweet menyatakan bahwa RUU TNI pantas disahkan karena dianggap dapat memperkuat pertahanan negara. **Di sisi lain**, banyak pula tweet yang mengekspresikan kekecewaan dan kekhawatiran, **dengan beberapa di antaranya** berargumen bahwa proses pengesahan tidak dipertimbangkan secara matang dan berpotensi menimbulkan efek negatif. **Oleh karena itu**, untuk menilai kelayakan pengesahan RUU TNI, diperlukan analisis yang mengacu pada data kebijakan, dampak yang terukur, serta pertimbangan konstitusional, bukan semata‚Äëmata pada jumlah pendapat yang ada.  \n",
      "\n",
      "**respons_chatbot_modifikasi**  \n",
      "Berdasarkan informasi dari tweet yang diberikan, terdapat beragam pendapat mengenai pengesahan RUU TNI. Sebagai contoh, beberapa tweet menyatakan bahwa RUU TNI pantas disahkan karena dianggap dapat memperkuat pertahanan negara. Di sisi lain, banyak pula tweet yang mengekspresikan kekecewaan dan kekhawatiran, dengan beberapa di antaranya berargumen bahwa proses pengesahan tidak dipertimbangkan secara matang dan berpotensi menimbulkan efek negatif. Oleh karena itu, untuk menilai kelayakan pengesahan RUU TNI, diperlukan analisis yang mengacu pada data kebijakan, dampak yang terukur, serta pertimbangan konstitusional, bukan semata‚Äëmata pada jumlah pendapat yang ada.  \n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"instructions:\n",
    "  task: \"Modifikasi respons chatbot yang mengandung logical fallacy.\"\n",
    "  persona: \"Ahli linguistik yang terampil dalam menganalisis struktur argumen, mengidentifikasi logical fallacy, dan memahami thematic progression.\"\n",
    "  method: >\n",
    "    1. Identifikasi logical fallacy dalam respons chatbot.\n",
    "    2. Analisis masalah thematic progression yang terdeteksi.\n",
    "    3. Lakukan modifikasi berdasarkan hasil analisis dari langkah 1‚Äì2.\n",
    "  output_format: >\n",
    "    paragraf dengan isian:\n",
    "      - 'respons_chatbot' (respons asli)\n",
    "      - 'respons_chatbot_sebelumnya' (bagian bermasalah)\n",
    "      - 'respons_chatbot_setelahnya' (bagian yang sudah diperbaiki)\n",
    "      - 'respons_chatbot_modifikasi' (respons lengkap setelah modifikasi)\n",
    "  handling_unknown: >\n",
    "    Jika tidak ditemukan logical fallacy yang perlu diperbaiki, kosongkan field modifikasi,\n",
    "    beri penjelasan dalam 'penjelasan_modifikasi', dan isi hanya 'respons_chatbot' (respons asli).\n",
    "\n",
    "context:\n",
    "input_queries:\n",
    "  respons_chatbot: >\n",
    "    {jawaban}\n",
    "  logical_fallacy: {final_label}\n",
    "  thematic_progression_problems: {tp_problems}\n",
    "\n",
    "respons_chatbot_sebelumnya: \"\"\n",
    "respons_chatbot_setelahnya: \"\"\n",
    "respons_chatbot_modifikasi: \"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "modification_response = response.content \n",
    "print(f\"{modification_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
